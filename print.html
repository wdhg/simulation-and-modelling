<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>60020 Simulation and Modelling</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="preface.html"><strong aria-hidden="true">1.</strong> Preface</a></li><li class="chapter-item expanded "><a href="operational-laws.html"><strong aria-hidden="true">2.</strong> Operational Laws</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="operational-laws/the-flow-balance-assumption.html"><strong aria-hidden="true">2.1.</strong> The Flow Balance Assumption</a></li><li class="chapter-item expanded "><a href="operational-laws/open-and-closed-systems.html"><strong aria-hidden="true">2.2.</strong> Open and Closed Systems</a></li><li class="chapter-item expanded "><a href="operational-laws/resources.html"><strong aria-hidden="true">2.3.</strong> Resources</a></li><li class="chapter-item expanded "><a href="operational-laws/the-utilisation-law.html"><strong aria-hidden="true">2.4.</strong> The Utilisation Law</a></li><li class="chapter-item expanded "><a href="operational-laws/littles-law.html"><strong aria-hidden="true">2.5.</strong> Little's Law</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="operational-laws/littles-law/the-response-time-law.html"><strong aria-hidden="true">2.5.1.</strong> The Response Time Law</a></li></ol></li><li class="chapter-item expanded "><a href="operational-laws/forced-flow-law.html"><strong aria-hidden="true">2.6.</strong> Forced Flow Law</a></li><li class="chapter-item expanded "><a href="operational-laws/the-service-demand-bottleneck-laws.html"><strong aria-hidden="true">2.7.</strong> The Service Demand/Bottleneck Laws</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="operational-laws/the-service-demand-bottleneck-laws/bottlenecks-and-throughput-bounds.html"><strong aria-hidden="true">2.7.1.</strong> Bottlenecks and Throughtput Bounds</a></li><li class="chapter-item expanded "><a href="operational-laws/the-service-demand-bottleneck-laws/response-time-bounds.html"><strong aria-hidden="true">2.7.2.</strong> Response Time Bounds</a></li><li class="chapter-item expanded "><a href="operational-laws/the-service-demand-bottleneck-laws/performance-optimisation.html"><strong aria-hidden="true">2.7.3.</strong> Performance Optimisation</a></li></ol></li><li class="chapter-item expanded "><a href="operational-laws/traffic-equations.html"><strong aria-hidden="true">2.8.</strong> Traffic Equations</a></li></ol></li><li class="chapter-item expanded "><a href="poisson-processes.html"><strong aria-hidden="true">3.</strong> Poisson Processes</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="poisson-processes/properties-of-the-exponential-distribution.html"><strong aria-hidden="true">3.1.</strong> Properties of the Exponential Distribution</a></li><li class="chapter-item expanded "><a href="poisson-processes/merging-poisson-processes.html"><strong aria-hidden="true">3.2.</strong> Merging Poisson Processes</a></li><li class="chapter-item expanded "><a href="poisson-processes/splitting-poisson-processes.html"><strong aria-hidden="true">3.3.</strong> Splitting Poisson Processes</a></li></ol></li><li class="chapter-item expanded "><a href="simulation.html"><strong aria-hidden="true">4.</strong> Simulation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="simulation/monte-carlo.html"><strong aria-hidden="true">4.1.</strong> Monte Carlo</a></li><li class="chapter-item expanded "><a href="simulation/discrete-time-simulation.html"><strong aria-hidden="true">4.2.</strong> Discrete-Time Simulation</a></li><li class="chapter-item expanded "><a href="simulation/discrete-event-simulation.html"><strong aria-hidden="true">4.3.</strong> Discrete-Event Simulation (DES)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="simulation/discrete-event-simulation/example-of-a-single-server-fifo-queue.html"><strong aria-hidden="true">4.3.1.</strong> Example of a Single-server FIFO Queue</a></li></ol></li><li class="chapter-item expanded "><a href="simulation/designing-a-simulation-model.html"><strong aria-hidden="true">4.4.</strong> Designing a Simulation Model</a></li></ol></li><li class="chapter-item expanded "><a href="confidence-intervals.html"><strong aria-hidden="true">5.</strong> Confidence Intervals</a></li><li class="chapter-item expanded "><a href="distribution-sampling.html"><strong aria-hidden="true">6.</strong> Distribution Sampling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="distribution-sampling/inverse-transform-method.html"><strong aria-hidden="true">6.1.</strong> Inverse Transform Method</a></li><li class="chapter-item expanded "><a href="distribution-sampling/acceptance-rejection-method.html"><strong aria-hidden="true">6.2.</strong> Acceptance-Rejection (AR) Method</a></li><li class="chapter-item expanded "><a href="distribution-sampling/convolution-method.html"><strong aria-hidden="true">6.3.</strong> Convolution Method</a></li><li class="chapter-item expanded "><a href="distribution-sampling/sampling-discrete-distributions.html"><strong aria-hidden="true">6.4.</strong> Sampling Discrete Distributions</a></li></ol></li><li class="chapter-item expanded "><a href="continuous-time-markov-chains.html"><strong aria-hidden="true">7.</strong> Continuous-Time Markov Chains (CTMCs)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="continuous-time-markov-chains/steady-state-solution-of-a-markov-process.html"><strong aria-hidden="true">7.1.</strong> Steady-state Solution of a Markov Process</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="continuous-time-markov-chains/steady-state-solution-of-a-markov-process/derivation-of-balance-equations.html"><strong aria-hidden="true">7.1.1.</strong> Derivation of Balance Equations</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems.html"><strong aria-hidden="true">8.</strong> Analytical Modelling: Queueing Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/marvokian-queueing-theory.html"><strong aria-hidden="true">8.1.</strong> Markovian Queueing Theory</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/marvokian-queueing-theory/kendalls-notation.html"><strong aria-hidden="true">8.1.1.</strong> Kendall's Notation</a></li></ol></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/the-mm1-queue.html"><strong aria-hidden="true">8.2.</strong> The M/M/1 Queue</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/the-mm1-queue/steady-state-distribution.html"><strong aria-hidden="true">8.2.1.</strong> Steady-state Distribution</a></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/the-mm1-queue/performance-indicies.html"><strong aria-hidden="true">8.2.2.</strong> Performance Indicies</a></li></ol></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/state-dependent-mm1-queue.html"><strong aria-hidden="true">8.3.</strong> State-dependent M/M/1 Queue</a></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/multiple-parallel-servers-mmc-queue.html"><strong aria-hidden="true">8.4.</strong> Multiple Parallel Servers M/M/c Queue</a></li><li class="chapter-item expanded "><a href="analytical-modelling-queueing-systems/infinite-parallel-servers-mminf-queue.html"><strong aria-hidden="true">8.5.</strong> Infinite Parallel Servers M/M/∞ Queue</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="cheatsheet.html">Cheatsheet</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">60020 Simulation and Modelling</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="preface"><a class="header" href="#preface">Preface</a></h1>
<p>This book contains my notes for course 60020 Simulation and Modelling by <a href="http://wp.doc.ic.ac.uk/ajf/">Tony Field</a> and <a href="http://wp.doc.ic.ac.uk/gcasale/">Giuliano Casale</a> at Imperial College London.</p>
<p>This book's source can be found <a href="https://github.com/wdhg/simulation-and-modelling">here</a>. Please feel free to submit any issues / pull requests if anything is wrong or unclear.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="operational-laws"><a class="header" href="#operational-laws">Operational Laws</a></h1>
<p>Given an arbitrary system (real, simulated, etc), if measurements can be made upon it then the 'operational laws' link these quantities together.</p>
<p>For example, take an &quot;open&quot; system (more on this later) which has arrivals entering it and completions exiting it:</p>
<pre><code>
  Arrivals        Completions
  -------&gt;(System)----------&gt;

</code></pre>
<p>For an amount of time \( T \), let:</p>
<ul>
<li>\( A \) represent the number of a arrivals</li>
<li>\( C \) represent the number of completions</li>
</ul>
<p>From this, we can begin to determine three relationships:</p>
<ol>
<li>The <em>arrival rate</em> is \( \lambda = {A \over T} \) (arrivals per unit time)</li>
<li>The <em>average inter-arrival time</em> is \( \lambda^{-1} = {T \over A} \) (average amount of time between arrivals)</li>
<li>The <em>throughput (traffic rate)</em> is \( X = {C \over T} \) (completions per unit time)</li>
</ol>
<p>(Note that throughput can be meassured on any arc).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-flow-balance-assumption"><a class="header" href="#the-flow-balance-assumption">The Flow Balance Assumption</a></h1>
<p>Typically the number of arrivals is equal to the number of completions (i.e. \( \lambda = X \)). This is the case when either the number of arrivals and completions are equal (\( A = C \)) or if their difference (\( A - C \)) is small in comparison to them. A system that is in <em>equilibrium</em> (or <em>steady state</em>) must satisfy this.</p>
<p>If over time (as \( T \rightarrow \infty \)) this assumption does not hold, then the system is fundamentally unstable.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="open-and-closed-systems"><a class="header" href="#open-and-closed-systems">Open and Closed Systems</a></h1>
<p>An <strong>open system</strong> is one where jobs can flow in and out of it freely. As a result, the number of jobs in the system can vary over time.</p>
<p>In a <strong>closed system</strong>, the number of jobs circulating around is fixed to some value \( N \). An example of a closed system is:</p>
<pre><code>
  *------------------*
  |                  |
  |                  |
  |                  |
  *----&gt;(System)-----*

</code></pre>
<p>The throughput of this example system is the traffic rate on the looping (ingoing and outgoing) arc.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="resources"><a class="header" href="#resources">Resources</a></h1>
<p>If a resource (server, mutex, network port, etc) is busy for a total time of \( B \), then:</p>
<ol>
<li>The <em>utilisation</em> of that resource is \( U = {B \over T} \) (the proportion of time that the resource is being used)</li>
<li>The <em>average service time</em> of each job at the resource is \( S = {B \over C} \)</li>
<li>The <em>service rate</em> is \( \mu = S^{-1} = {C \over B} \)</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-utilisation-law"><a class="header" href="#the-utilisation-law">The Utilisation Law</a></h1>
<p>\[
\begin{align}
U &amp;= {B \over T} \\
&amp;= {B \over T} * {C \over C} \\
&amp;= {B \over C} * {C \over T} \\
&amp;= XS
\end{align}
\]</p>
<p>Since service rates are used a lot, this also comes out to \( U = {X \over \mu} \). Note that because \( B \le T \) and \( U = {B \over T} \) then \( U \le 1 \), so using \( U = {X \over \mu} \) we know that \( {X \over \mu} \le 1 \) so \(X \le \mu \). What this means is that the throughput must always be less than or equal to the service rate for the system to be stable.</p>
<p>Note that in the situation where the arrival rate equals the service rate (\( \lambda = \mu \)) this might seem like it would be a stable system but in general (and depending on the distributions of the inter-arrival times and service times) it is actually unstable (more on this later).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="littles-law"><a class="header" href="#littles-law">Little's Law</a></h1>
<p>Given an open system, if the population of the system (\( A - C \)) was plotted over an observation period \( (0, T) \):</p>
<pre><code>
    A - C
        ^                      Total area = I
       4|
        |
       3|             +-----+                             +---+
        |             |     |                             |   |
       2|       +-----+     +---+       +---+     +-------+   +---+
  I/T- -|- - - -|- - -|- - -|- -|- - - -|- -|- - -|- - - -|- -|- -|
       1|-------+     |     |   +-------+   +-----+       |   |   |
        |       |     |     |   |       |   |     |       |   |   |
       0*---------------------------------------------------------------&gt;
        0       t1    t2   t3  t4      t5   t6    t7      t8  t9  T   Time

</code></pre>
<p>Then the total area under the graph \( I \) would be in &quot;request-seconds&quot;. Then we have:</p>
<ol>
<li>The <em>average number of jobs</em> in the system is \( N = {I \over T} \)</li>
<li>The <em>average response time</em> (the average time each job spends in the system) is \( R = {I \over C} \)</li>
</ol>
<p>Using these, Little's Law can be derived:</p>
<p>\[
\begin{aligned}
N &amp;= {I \over T} \\
&amp;= {I \over T} * {C \over C} \\
&amp;= {C \over T} * {I \over C} \\
&amp;= XR
\end{aligned}
\]</p>
<p>This means that the average number of jobs in a system is equal to the product of the throughput and the average response time.</p>
<p>Little's Law works on <em>any</em> system (or subsystem) in equilibrium. When a system is not yet under equilibrium (say, for example, the system is warming up) then it does not apply.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-response-time-law"><a class="header" href="#the-response-time-law">The Response Time Law</a></h1>
<p>If a closed system has a fixed population of \( N \) users (or customers, packets, jobs, etc) working in &quot;think/compute&quot; mode (i.e. they have a &quot;think time&quot; \( Z \) between the completion of a job and the submission of the next) then this is a special case of Little's Law:</p>
<pre><code>
  N users with think time Z

           +-()-+
           + () +
    *------+ .. +&lt;-----*
    |      +-()-+      |
    |                  |
    |                  |
    |                  |
    *----&gt;(System)-----*

       Response time R

</code></pre>
<p>The average total time for each cycle is \( R + Z \) so from Little's Law: \( N = X * (R + Z) \) or rearranged as \( R = {N \over X} - Z \). Note this <strong>only</strong> applies for the entire closed system, any subsystem will still obey Little's Law.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forced-flow-law"><a class="header" href="#forced-flow-law">Forced Flow Law</a></h1>
<p>Take a system which contains multiple resources inside it and has \( C \) completions. Consider an arbitrary resource \( k \) inside the system, with \( C_k \) completions:</p>
<pre><code>
      *------------------*
      |           C_k    | C
  ---&gt;| ... --&gt;(k)--&gt; ...|---&gt;
      |                  |
      *------------------*
            System

</code></pre>
<p>Note that \( C_k \) can be <strong>more</strong> than \( C \) if jobs go to resource \( k \) multiple times inside the system.</p>
<p>Let \( V_k = {C_k \over C} \) be the average number of visits each job makes to resource \( k \). Rearranging and dividing by both sides by \( T \) gives \( X_k = V_k X \), where \( X_k \) is the throughput of resource \( k \).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-service-demandbottleneck-laws"><a class="header" href="#the-service-demandbottleneck-laws">The Service Demand/Bottleneck Laws</a></h1>
<p>Given an arbitrary node \( k \) inside an arbitrary system, the <em>Service demand</em> \( D_k = V_k S_k \) is the product of average number of visits \( V_k \) and the average service time \( S_k \).</p>
<p>If we multiply the RHS of this equation by \( X_k \over X_k \):</p>
<p>\[
\begin{aligned}
D_k &amp;= V_k S_k {X_k \over X_k} \\
&amp;= \left( S_k X_k \right) \left( {V_k \over X_k} \right) \\
&amp;= {U_k \over X}
\end{aligned}
\]</p>
<p>where X is the global throughput of the system. Rearranging gives \( U_k = D_k X \), whichs shows that every \( U_k \) and \( V_k \) is linked by the global throughput.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bottlenecks-and-throughtput-bounds"><a class="header" href="#bottlenecks-and-throughtput-bounds">Bottlenecks and Throughtput Bounds</a></h1>
<p>Since \( U_k = D_k X \) and \( U_k \le 1 \), then we know \( X \le {1 \over D_k} \) for every node \( k \) in the system. From this we get that \( X \le {1 \over D_max} \) where \( D_{max} \) is the maximum of \( D_k \).</p>
<p>In a system under heavy load we can say that \( U_{max} \approx 1 \) and \( X \approx {1 \over D_{max}} \). What this means is that \( 1 \over D_{max} \) is the <strong>upper asymptotic bound on throughput under heavy load</strong>, and the resource with the highest demand \( D_{max} \) is the <strong>bottleneck</strong> resource of the system. Note that if the system is open, then \( \lambda = X \) so we also require that \( \lambda \le {1 \over D_{max}} \) for the system to be stable.</p>
<p>In a system under light load jobs are never queued and so the average total time they spend at each resource \( k \) is just \( D_k \) (remember \( D_k \) is the product of the average number of visits per job and the average service time at that resource), so we can say that for the entire system the response time \( R \) is the sum of all service demands: \(R = D_1 + D_2 + ... + D_k \). In a closed system, we can apply this to the response time law:</p>
<p>\[
\begin{aligned}
X &amp;= {N \over (R + Z)} \\
&amp;= {N \over (D + Z)}
\end{aligned}
\]</p>
<p>where \( D = D_1 + D_2 + ... + D_k \). This means that \( N \over (D + Z) \) is the <strong>upper asymptotic bound on throughput under light load</strong>.</p>
<p>Combining these two limits, we can say that in general: \( X \le min \left( {1 \over D_{max}}, {N \over (D + Z)} \right) \). Note that in an open system we say that \( Z = 0 \) but we also recognise that \( N \) is not fixed. The bound still applies, however it is not as tight as in a closed system.</p>
<p>When throughput is plotted against the number of jobs, it typically looks like this:</p>
<p><img src="operational-laws/the-service-demand-bottleneck-laws/./images/throughput-plot.png" alt="A graph of throughput X against number of jobs N being bounded" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="response-time-bounds"><a class="header" href="#response-time-bounds">Response Time Bounds</a></h1>
<p>Just like with throughput, we can calculate the bounds for response time. In a system under high load, since the throughtput is bounded by \( X \le {1 \over D_{max}} \) we know that:</p>
<p>\[
\begin{aligned}
R &amp;= {N \over X} - Z \\
&amp;\le N D_{max} - Z
\end{aligned}
\]</p>
<p>In a system under low load, every job experiences the average service demand at each node without needing to queue. That means that the response time is equal to the sum of the service demands \( D \), thus \( R \ge D \).</p>
<p>Putting these together we get \( R \ge max \left( D, N * D_{max} - Z \right) \). When response time is plotted against number of jobs it looks like:</p>
<p><img src="operational-laws/the-service-demand-bottleneck-laws/./images/response-time-plot.png" alt="A graph of response time R against number of jobs N being bounded" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-optimisation"><a class="header" href="#performance-optimisation">Performance Optimisation</a></h1>
<p><em>Performance optitmisation</em> means / involves:</p>
<ol>
<li>Understanding / modelling the system</li>
<li>Finding the bottleneck node</li>
<li>Fixing the bottleneck</li>
</ol>
<p>When you fix the bottleneck you change the bounds / limits described in the previous two sections. For example, these two graphs show how optimisations can affect the shape of the throughput \( X \) or response time \( R \) against number of jobs \( N \) plots:</p>
<p><img src="operational-laws/the-service-demand-bottleneck-laws/./images/throughput-optimisation-plot.png" alt="" />
<img src="operational-laws/the-service-demand-bottleneck-laws/./images/response-time-optimisation-plot.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="traffic-equations"><a class="header" href="#traffic-equations">Traffic Equations</a></h1>
<p>Consider an arbitrary system with \( n \) nodes, where each node \( k \) in \( 1 \le k \le n \) has \( C_k \) completions. When the system is at equilibrium, the number of arrivals is equal to the system to the number of completions \( A = C \), and each job arrives exactly once to the system.</p>
<p>Now consider two arbitrary and distinct nodes \( i \) and \( j \) where \( 1 \le i, j \le n \). Assume that a job that comletes at \( i \) has a fixed probability \( r_{ij} \) of moving to node \( j \). Then for any node \( k \), the number of completions \( C_k \) must equal the sum of:</p>
<ol>
<li>the number of arrivals to the system \( A \) multiplied by the probability that an arriving job will move to node \( k \) directly, denoted as \( a_k \).</li>
<li>the sum of the products of every node's number of completions and probability that a job will move to \( k \) (note this includes the cyclic arc from \( k \) to \( k \)).</li>
</ol>
<p>\[
C_k = A a_k + C_1 r_{1k} + C_2 r_{2k} + \ldots + C_n r_{nk}
\]</p>
<p>If both sides are divided by the total number of completions in the system \( C \) we get an equation for the number of visits \(V_k = {C_k \over C} \):</p>
<p>\[
V_k = a_k + V_1 r_{1k} + V_2 r_{2k} + \ldots + V_n r_{nk}
\]</p>
<p>Note that \( A = C \) hence why it disappears from \(A a_k \).</p>
<p>If we divide by the total time \( T \) instead, we get an equation for the node throughput \( X_k \):</p>
<p>\[
X_k = \gamma_k + X_1 r_{1k} + X_2 * r_{2k} + \ldots + X_n * r_{nk}
\]</p>
<p>where \( \gamma_k = X a_k \) is the direct contribution to throughput from external arrivals.</p>
<p>We can now take these equations and turn them into vector equations:</p>
<p>\[
\vec{V} (\boldsymbol{I} - \boldsymbol{R}) = \vec{a}
\]
\[
\vec{X} (\boldsymbol{I} - \boldsymbol{R}) = \vec{\gamma}
\]</p>
<p>where:</p>
<ul>
<li>\( \vec{V} \) is the vector of number of visits for each node.</li>
<li>\( \boldsymbol{I} \) is the identity matrix.</li>
<li>\( \boldsymbol{R} \) is the maxtrix of probabilities that a job goes from node \( i \) to node \( j \).</li>
<li>\( \vec{\gamma} \) is the vector of direct contributions to throughput from external arrivals for each node.</li>
</ul>
<p>Note that often we use arrival rate of node \( i \) (denoted as \( λ_i \)) instead of throughput. Since arrival rate is the same as throughput, we can write:</p>
<p>\[
\vec{\lambda} (\boldsymbol{I} - \boldsymbol{R}) = \vec{\gamma}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="poisson-processes"><a class="header" href="#poisson-processes">Poisson Processes</a></h1>
<p>A <em>Poisson arrival processes</em> is an arrival stream where the inter-arrival times \( T \) are both independent and <em>exponentially distributed</em>:</p>
<p>\[
P(T \le t) = 1 - e^{(-\lambda t)}
\]</p>
<p>Here, \( \lambda \) is often called the processes' &quot;rate&quot; parameter and is equal to the reciprocal of the average inter-arrival time.</p>
<p>Since the inter-arrival times are exponentially distributed, for a fixed time window the number of arrivals is <em>poisson distributed</em>:</p>
<p>\[
P(A_t = n) = {(\lambda t)^n * e^{-λt} \over n!}
\]</p>
<p>where \( A_t \) is the number of arrivals for time interval \( t \).</p>
<p>Poisson processes are often an effective approximation for real world random arrival processes as arrivals are typically:</p>
<ol>
<li>independent to each other.</li>
<li>ignorant of previous arrivals and the state of the system they are arriving at.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="properties-of-the-exponential-distribution"><a class="header" href="#properties-of-the-exponential-distribution">Properties of the Exponential Distribution</a></h1>
<p>Here are three properties of the exponential distribution that will be useful to recap:</p>
<ol>
<li>The exponential distribution is <em>memoryless</em>, meaning that the future is independent to the past:</li>
</ol>
<p>\[
\begin{aligned}
P(X \le t + s | X &gt; t) &amp;= 1 - {P(X \gt t + s \land X \gt t) \over P(X &gt; t)} \\
&amp;= 1 - {P(X \gt t + s) \over P(X \gt t)} \\
&amp;= 1 - {e^{-\lambda (t + s)} \over e^{-λt}} \\
&amp;= 1 - {e^{-\lambda s} * e^{-\lambda t} \over e^{-\lambda t}} \\
&amp;= 1 - e^{-\lambda s} \\
&amp;= P(X \le s)
\end{aligned}
\]</p>
<ol start="2">
<li>If \( X_1 \sim exp(\lambda_1) \) and \( X_2 \sim exp(\lambda_2) \) then \( min(X_1, X_2) \sim exp(\lambda_1 + \lambda_2) \):</li>
</ol>
<p>\[
\begin{aligned}
P(min(X_1, X_2) \le t) &amp;= 1 - P(min(X_1, X_2) \gt t) \\
&amp;= 1 - P(X_1 \gt t \land X_2 \gt t) \\
&amp;= 1 - e^{-\lambda_1 t} e^{-\lambda_2 t} \\
&amp;= 1 - e^{-t(\lambda_1 + \lambda_2)}
\end{aligned}
\]</p>
<ol start="3">
<li>If \( X_1 \sim exp(\lambda_1) \) and \( X_2 \sim exp(\lambda_2) \) then</li>
</ol>
<p>\[
\begin{aligned}
P(X_1 &lt; X_2) &amp;= \int_0^{\infty} P(X_1 \lt X_2 | X_1 = x) * \lambda_1 * e^{-\lambda_1 x} dx \\
&amp;= \int_0^{\infty} P(X_2 \gt x) * λ_1 * e^{-\lambda_1 * x} dx \\
&amp;= \int_0^{\infty} e^{-\lambda_2 x} * \lambda_1 * e^{-\lambda_1 x} dx \\
&amp;= \lambda_1 \int_0^{\infty} e^{-x(\lambda_1 + \lambda_2)} dx \\
&amp;= \lambda_1 \left[ {-e^{-x(\lambda_1 + \lambda_2)} \over \lambda_1 + \lambda_2}  \right]_0^\infty \\
&amp;= \lambda_1 {0 - (-1) \over \lambda_1 + \lambda_2}  \\
&amp;= {\lambda_1 \over \lambda_1 + \lambda_2} \\
\end{aligned}
\]</p>
<p>and therefore by swapping \( X_1 \) and \( X_2 \):</p>
<p>\[
P(X_2 &lt; X_1) = {\lambda_2 \over \lambda_1 + \lambda_2}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merging-poisson-processes"><a class="header" href="#merging-poisson-processes">Merging Poisson Processes</a></h1>
<p>When two independent Poisson processes with rates \( λ_1 \) and \( λ_2 \) are merged together, the result is also a Poisson process with rate \( λ_1 + λ_2 \).</p>
<h3 id="proof"><a class="header" href="#proof">Proof</a></h3>
<p>Let:</p>
<ul>
<li>\( T_1 \) and \( T_2 \) be the time until the next arrival for two Poisson processes.</li>
<li>\( T \) be the time until the next arrival for the merged process.</li>
</ul>
<p>Then we get:</p>
<p>\[
\begin{aligned}
P(T \le t) &amp;= P(min(T_1, T_2) \le t) \\
&amp;= 1 - e^{-t(λ_1 + λ_2)}
\end{aligned}
\]</p>
<p>Note that this is described more in detail in the <a href="poisson-processes/./properties-of-the-exponential-distribution.html">Properties of the Exponential Distribution section</a>.</p>
<p>This shows that the inter-arrival times of the merged process is exponential distributed, and so the merged process is Poisson.</p>
<h2 id="generalised-merging"><a class="header" href="#generalised-merging">Generalised Merging</a></h2>
<p>We can also generalise this for \( n \ge 2 \) processes. Consider a binary tree of merges. Since the output of a merge is Poisson, it can be merged with another process, thus creating a chain of merges:</p>
<pre><code>  ()()
   \/ merge
   ()()
    \/ merge
    ()()
     \/ merge
     ()
</code></pre>
<h2 id="probability-of-arrival-orders"><a class="header" href="#probability-of-arrival-orders">Probability of Arrival Orders</a></h2>
<p>The probability that the first arrival will come from the first stream is given by:</p>
<p>\[
P(T_1 \lt T_2) = {\lambda_1 \over \lambda_1 + \lambda_2}
\]</p>
<p>and likewise the probability that the first arrival is from the second stream is:</p>
<p>\[
P(T_2 \lt T_1) = {\lambda_2 \over \lambda_1 + \lambda_2}
\]</p>
<p>Note that this is described more in detail in the <a href="poisson-processes/./properties-of-the-exponential-distribution.html">Properties of the Exponential Distribution section</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="splitting-poisson-processes"><a class="header" href="#splitting-poisson-processes">Splitting Poisson Processes</a></h1>
<p>If we split a Poisson process with rate \( \lambda \) into two streams, such that there is:</p>
<ul>
<li>chance \( p \) (\( 0 \le p \le 1\)) that the arrival will go to the first stream.</li>
<li>chance \( 1 - p \0 that the arrival will go into the second stream.</li>
</ul>
<p>then the resulting two processes will independent Poisson processes with rates \( \lambda p \) and \( \lambda (1 - p) \) respectively. From this we can say that:</p>
<p>\[
P(N_1(t) = m) = {(\lambda t p)^m * e^{-\lambda t p} \over m!}
\]</p>
<p>and</p>
<p>\[
P(N_2(t) = n) = {(\lambda t (1 - p))^n * e^{-\lambda t (1 - p)} \over n!}
\]</p>
<p>where:</p>
<ul>
<li>\( t \) is the time interval.</li>
<li>\( N_1(t) \), \( N_2(t) \) are the number of arrivals seen at both output streams respectively during interval \( t \).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simulation"><a class="header" href="#simulation">Simulation</a></h1>
<p>Broadly there are three classes of simulation: </p>
<ul>
<li>Monte Carlo.</li>
<li>Discrete time.</li>
<li>Discrete event.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="monte-carlo"><a class="header" href="#monte-carlo">Monte Carlo</a></h1>
<p>Run multiple 'one shot' experiments using random numbers (no state, just make random observations and repeat many times) and aggregate the results.</p>
<p>For example, \( \pi \) can be estimated using Monte Carlo simulation:</p>
<ol>
<li>Take a circle of radius \( r \) and a square with side length \( 2r \).</li>
<li>Pick random points inside this shape.</li>
<li>Calculate <code>No. in circle / No. in square</code> to estimate \( \pi \over 4 \) (by the ratio of the areas \( \pi r^2 \over (2 \pi)^2 \) )</li>
</ol>
<p><img src="simulation/./images/monte-carlo-pi.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discrete-time-simulation"><a class="header" href="#discrete-time-simulation">Discrete-Time Simulation</a></h1>
<p>Given a state transition system (e.g. nodes with arcs) take \( n \) steps randomly throught the system, moving from one state to the next in each discrete step. There may or may not be a notion of time in the discrete steps made.</p>
<p>For example, consider a game of Monopoly where you want to find the probability of landing on each board position in the game. This can be done by starting at GO, simulating \( n \) dice rolls, following the rules of the game (including chance and community chest cards), and counting how many times each tile is landed on.</p>
<p><img src="simulation/./images/monopoly.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discrete-event-simulation-des"><a class="header" href="#discrete-event-simulation-des">Discrete-Event Simulation (DES)</a></h1>
<p>Similar to discrete time, steps are made through a state transition system, but instead these steps are triggered by discrete events in continuous time. To do this, there is a single global clock that dictates the virtual time of the simulation. The triggering events are scheduled in order of time, and when an event occurs the global clock is updated to the timestamp of the event.</p>
<pre><code>
                            Virtual  ---&gt; Direction of time
                             Time
                               |
                               V
               |---*------*----*--------*---*-------*------&gt; ...
    Timestamp: 0   3      8    9       19  21      28

</code></pre>
<p>Events can also update the state of the simulation and queue future events.</p>
<p>Since events don't occur in order of generation but rather in order of their randomly sampled timestamps, discrete-event simulation is therefore an asychronous model of time. Discrete-time simulation on the other hand is a synchronous model of time as events occur in order of their generation (e.g. in a Monopoly simulation, the state gets updated as soon as the dice is rolled).</p>
<h2 id="in-practice"><a class="header" href="#in-practice">In Practice</a></h2>
<p>In practice a discrete-event simulation has:</p>
<ul>
<li>Continuous time (i.e. a floating-point number)</li>
<li>A collection of variables (both discrete and continuous) that constitute the simulation state.</li>
<li>A priority queue of events, ordered by their timestamp.</li>
<li>A scheduler adds new events to the priority queue.</li>
<li>A descheduler removes events from the priority queue.</li>
<li>Measurement code will also be required to get output data from the simulation.</li>
</ul>
<h2 id="evolution-of-time"><a class="header" href="#evolution-of-time">Evolution of Time</a></h2>
<pre><code>    History &lt;-- Virtual --&gt; Future
                 Time
                   |
                   V
                Event 1           Event 2
    |--------------*-----------------*------------------&gt; ...
                  t1                t2
                   |                 |
                   |&lt;---------------&gt;|
                      Δt = t2 - t1
</code></pre>
<p>In the diagram above, Event 1 at time \( t_1 \) schedules Event 2 at time \( t_2 \). To do this, an amount of time \( \Delta t \) is added to \( t_1 \) to get \( t_2 \). \( \Delta t \) is thus the interarrival time of the events, and so it can be modelled as a random variable. We'll need to be able to sample \( \Delta t \) by sampling its distribution (more on this later).</p>
<h2 id="discrete-time-to-discrete-event-example"><a class="header" href="#discrete-time-to-discrete-event-example">Discrete-Time to Discrete-Event Example</a></h2>
<p>Using the Monopoly example, to change it from a discrete time simulation to a discrete event simulation we can model the move times explicitly using some random variable \( T \) with a specified distribution. Then at each move, we can add to the current time a sample of this distribution to progress through time (e.g. <code>current time + sample of T</code>). However if we want to simulate \( P \) players who roll their dice independently, we will need to think of a way to resolve the issue of updating time and shared resources (e.g. cards). This can be done using a sequence of move events in time order and controlled access to shared resources (e.g. via queueing).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="example-of-a-single-server-fifo-queue"><a class="header" href="#example-of-a-single-server-fifo-queue">Example of a Single-server FIFO Queue</a></h1>
<p>Consider a finite single-server queue with a mean interarrival time \( \lambda \), mean service rate \( \mu \), and queue capacity of \( N \):</p>
<p><img src="simulation/discrete-event-simulation/./images/single-server-queue.png" alt="A single-server queue diagram" /></p>
<p>We can model this queue using the following graph, where the number of each state represents the length of the queue:</p>
<p><img src="simulation/discrete-event-simulation/./images/single-server-queue-state-diagram.png" alt="The state diagram of a single-server queue of length N" /></p>
<p>As shown in this diagram, two events are required to model this queue: <code>Arrival</code> and <code>Completion</code>.</p>
<p>The timeline priority queue will contain <code>Arrival</code> and <code>Completion</code> events. Completing each event will update the state depending on the state of the simulation, described by the following rules / pseudocode:</p>
<pre><code>Let State = 0
Let N be the max queue length
Let there be a priority queue

Queue an Arrival at the start of the simulation
Get next event in queue

If the event is an Arrival:

  State += 1

  If State &lt; N:
    Queue a new Arrival

  If State == 1:
    Queue a new Completion

If the event is a Completion:

  State -= 1

  If State == N - 1:
    Queue a new Arrival

  If State &gt; 0:
    Queue a new Completion
</code></pre>
<p>Note that in this example the <code>Queue</code> steps implicitly sample the interarrival time for the specific events interarrival time distribution.</p>
<p><img src="simulation/discrete-event-simulation/./images/example-timeline.png" alt="An example timeline" /></p>
<p>Suppose a <code>Clear</code> event also needs to be added, which will reset the state to \( 0 \). If the state is not equal to \( 0 \) then </p>
<pre><code>Queue a Clear at the start of the simulation

If the event is a Clear:

  If state &gt; 0:
    Dequeue the Completion event

  If state == N:
    Queue a new arrival

  State = 0

  Queue a new Clear
</code></pre>
<p><img src="simulation/discrete-event-simulation/./images/single-server-queue-clear-example.png" alt="The state diagram with clear events added" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="designing-a-simulation-model"><a class="header" href="#designing-a-simulation-model">Designing a Simulation Model</a></h1>
<p>This section will run through designing a simulation model step-by-step using Monopoly as an example. Note that a lot of the examples will be dependent on the simulation implementation.</p>
<h2 id="1-identify-the-entities"><a class="header" href="#1-identify-the-entities">1. Identify the entities</a></h2>
<p>The most important entities would the player pieces. Depending on how the simulation is implemented, this could also include other things such as the board tiles (properties, jail, etc) and their cards.</p>
<h2 id="2-identify-the-model-states"><a class="header" href="#2-identify-the-model-states">2. Identify the model states</a></h2>
<p>In practice, these would be the state variables of the program. In terms of the example, these could include:</p>
<ul>
<li>The positions of player pieces.</li>
<li>The amount of money each player has.</li>
<li>Who owns which properties.</li>
<li>The buildings on each tile.</li>
</ul>
<h2 id="3-identify-the-types-of-events"><a class="header" href="#3-identify-the-types-of-events">3. Identify the types of events</a></h2>
<p>Events are what trigger state transitions, such as:</p>
<ul>
<li>Moving from dice rolls.</li>
<li>Chance and community chest cards.</li>
<li>Go to jail tile.</li>
</ul>
<p>Note that some events can be parameterisable.</p>
<h2 id="4-for-each-event"><a class="header" href="#4-for-each-event">4. For each event...</a></h2>
<h3 id="i-specify-how-the-event-changes-the-current-state-of-the-system"><a class="header" href="#i-specify-how-the-event-changes-the-current-state-of-the-system">i. Specify how the event changes the current state of the system</a></h3>
<ul>
<li>Rolling the dice will move a pieces position.</li>
<li>A piece that lands on a property owned by another player will cause them to pay rent.</li>
<li>Picking a card could cause a variety of other changes.</li>
</ul>
<h3 id="ii-identify-which-new-events-need-to-be-scheduled"><a class="header" href="#ii-identify-which-new-events-need-to-be-scheduled">ii. Identify which new events need to be scheduled</a></h3>
<ul>
<li>Rolling the dice will queue another dice roll for the next player.</li>
</ul>
<h2 id="5-write-code-to-perform-measurements"><a class="header" href="#5-write-code-to-perform-measurements">5. Write code to perform measurements</a></h2>
<ul>
<li>Counting the number of times each property is landed on.</li>
<li>Counting how much rent is collected at each property.</li>
</ul>
<h2 id="6-output-the-measurement-results-at-the-end-of-the-simulation"><a class="header" href="#6-output-the-measurement-results-at-the-end-of-the-simulation">6. Output the measurement results at the end of the simulation.</a></h2>
<p>Could be in the form of raw data and/or graphs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="confidence-intervals"><a class="header" href="#confidence-intervals">Confidence Intervals</a></h1>
<p>Given \( n \) observations \( X_i, 1 \le i \le n \) for an unknown mean \( \mu \), the \( 100 \alpha \% \) confidence interval for \( \mu \) is given by:</p>
<p>\[
\overline{X} \pm {t_{n - 1, 1 - \alpha / 2} * S \over \sqrt{n}}
\]</p>
<p>where \( t_{n - 1, 1 - \alpha / 2} \) is the result given by the t-distribution with \( n-1 \) degrees of freedom and a tail area of \( 1 - \alpha / 2 \). This confidence interval is <strong>exact</strong> (not an <strong>approximation</strong>) if:</p>
<p>\[
P \left( \overline{X} - {t_{n - 1, 1 - \alpha / 2} * S \over \sqrt{n}} \le \mu \le \overline{X} + {t_{n - 1, 1 - \alpha / 2} * S \over \sqrt{n}} \right) = \alpha
\]</p>
<p>In practice, the confidence interval is typically an <strong>approximate</strong> because of one or more of the following reasons:</p>
<ul>
<li>\( n \) is too small (note that being too &quot;small&quot; depends on the distribution of the measurements).</li>
<li>\( n \) is small and the measurements \( X_i \) are not normally distributed.</li>
<li>The measurements \( X_i \) are not independent of each other.</li>
</ul>
<h2 id="independent-measuring"><a class="header" href="#independent-measuring">Independent Measuring</a></h2>
<p>To ensure that the measurements \( X_i \) are made independently, they can be made by running \( n \) <strong>independent replications</strong> (simulations).</p>
<p>Another method would be to run a single simulation to the point of (approximate) equilibrium, running back-to-back fixed time batches of measurements, resetting the measurements made at the end of each epoch:</p>
<p><img src="./images/batched-observations.png" alt="" /></p>
<p>where measurement \( X_i \) is the measurement made from batch \( i \). If \( X_i \) is also a mean, then this is called the <strong>batched means</strong> method. However, an issue with this method is that sequential measurements \( X_i \) and \( X_{i + 1} \) may be dependent if the simulation enters some edge case state.</p>
<h2 id="dealing-with-dependent-measurements"><a class="header" href="#dealing-with-dependent-measurements">Dealing with Dependent Measurements</a></h2>
<p>If the measurements \( X_i \) are dependent, then the <strong>covariances</strong> must be taken into account to build an exact confidence interval. Looking back at the previous confidence interval, this makes the following assumption:</p>
<p>\[
VAR \left( \overline{X} \right) = {\sigma^2 \over n} + {1 \over n^2} \left[ 2 \sum_{i=1}^{n-1} \sum_{j=i+1}^{n} Cov(X_i, X_j) \right]
\]</p>
<p>Since covariances are typically positive, then the variance estimate \( S^2 \over n \) will become an <strong>under-estimate</strong> of the actual variance \( VAR \left( \overline{X} \right) \). This means that the computed confidence intervals are narrower than they should be.</p>
<h2 id="bounding-the-error-from-simulations"><a class="header" href="#bounding-the-error-from-simulations">Bounding the Error from Simulations</a></h2>
<p>The simulaton run length and/or number of observations collected could be adjusted to make the confidence interval half width less than or equal to some small percentage of the sample mean. That is:</p>
<p>\[
h \le c \overline{X}
\]</p>
<p>where:</p>
<ul>
<li>\( h \) is the confidence interval half width of the collected data.</li>
<li>\( c \) is some fixed small percentage.</li>
</ul>
<p>This is done by:</p>
<ol>
<li>Fixing \( c \) to the desired accuracy level, for example \( 10 \% \).</li>
<li>Run the simulation to obtain \( n \) independent (and if \( n \) is small, approximately normally-distributed) observations \( X_1, X_2, ... , X_n \).</li>
<li>Compute \( \overline{X} \) and \( S \), then use these values to compute the half width of the \(100 \alpha \% \) confidence interval \( h \):</li>
</ol>
<p>\[
h = {t_{n - 1,1 - \alpha / 2} * S \over \sqrt{n}}
\]</p>
<ol start="4">
<li>If \( h \gt c \overline{X} \) then increase the observation period and/or the number of replications (independent simulations) and repeat the experiment.</li>
</ol>
<p>Since this is a feedback loop until a certain threshold is reached, this process can clearly be automated.</p>
<h2 id="state-space-coverage"><a class="header" href="#state-space-coverage">State Space Coverage</a></h2>
<p>Take some arbitrary model and consider its underlying state space/transition system:</p>
<p><img src="./images/underlying-state-space.png" alt="" /></p>
<p>Assume that a simulation for this model is run for time \( T \) at (approximate) equilibrium and for every state \( s \) the time spent in state \( s \) is \( T_s \). This can be used to approximate the probability \( p_s \) of being in state \( s \):</p>
<p>\[
\hat{p}_s = {T_s \over T}
\]</p>
<p>Note that measures such as the waiting time \( W \) can either be calculated directly or in terms of \( \hat{p}_s \) using Little's Law; the answers will be the same.</p>
<p>The quality of the estimate \( \hat{p}_s \) clearly depends on \( T \), but it also depends on the distribution of \( p_s \) where \( s \in S \):</p>
<p><img src="./images/state-space-occupation.png" alt="" /></p>
<p>In this diagram, the coloured states are the largest subset of states \( S' \subseteq S \) such that:</p>
<p>\[
inf \{ p_i | i \in S' \} \ge sup \{ p_j | j \in S - S' \}
\]</p>
<p>and </p>
<p>\[
\sum_{i \in S'} p_i \le p_{max}
\]</p>
<p>for some \( p_{max} \). These two equations simply split the states into two sets, where \( S' \) contains the highest probability states and \( S - S' \) contains the lowest probability states, and this split is defined by the parameter \( p_{max} \).</p>
<p>The left model shows a system under light load, whereas the right model show a system under heavy load. The confidence interval for the left model will be narrower than the right.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distribution-sampling"><a class="header" href="#distribution-sampling">Distribution Sampling</a></h1>
<p>To be able to simulate models, the simulations have to be able to sample the underlying probability distributions. There are four commonly-used methods to do this:</p>
<ol>
<li>Inverse transform method.</li>
<li>Acceptance-Rejection (AR) method.</li>
<li>Convolution method.</li>
<li>Composition method.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="inverse-transform-method"><a class="header" href="#inverse-transform-method">Inverse Transform Method</a></h1>
<p>Assume that the goal is to sample the continuous random variable \( X \), which has a c.d.f \( F(x) = P(X \le x) \). Since \( F(x) \) is a c.d.f, there are a couple of properties to note:</p>
<ol>
<li>\(0 \le F(x) \le 1 \)</li>
<li>\( F(x) \) increases monotonically (i.e. at all points it is increasing in value).</li>
</ol>
<p>As a result, if we let \( U \sim U(0, 1) \) then we get:</p>
<p>\[
\begin{align}
P \left( X \le x \right) &amp;= P \left( F^{-1} (U) \le x \right) \\
&amp;= P \left( U \le F(x) \right) \\
&amp;= F(x)
\end{align}
\]</p>
<p>This demonstates that if \( F^{-1}(x) \) exists, then by setting \( F(X) \) (notice how it's \( X \) not \( x \) as we are dealing with sampling the random variable) equal to the uniform random variable \( 0 \le U \le 1 \) we can manipulate the equation to get \( X \) in terms of \( U \).</p>
<h3 id="example-1"><a class="header" href="#example-1">Example 1</a></h3>
<p>If \( X \sim U(a,b) \) then:</p>
<p>\[
F(x) = {x - a \over b - a}, \quad a \le x \le b
\]</p>
<p>From setting \( U = F(X) \) and inverting \( F \) we get:</p>
<p>\[
\begin{align}
U &amp;= F(X) \\
U &amp;= {X - a \over b - a} \\
X - a &amp;= U * (b - a) \\
X &amp;= U * (b - a) + a
\end{align}
\]</p>
<p>This also matches what we'd expect intuitively: \( U \sim U(0,1) \) so \( U * (b - a) + a \sim U(a,b) \).</p>
<h3 id="example-2"><a class="header" href="#example-2">Example 2</a></h3>
<p>If \( X \sim exp(\lambda) \) Then</p>
<p>\[
F(x) = 1 - e^{-\lambda x}, \quad X \ge 0
\]</p>
<p>From setting \( U = F(X) \) and inverting \( F \) we get:</p>
<p>\[
\begin{align}
U &amp;= 1 - e^{-\lambda X} \\
1 - U &amp;= e^{-\lambda X} \\
log_e(1 - U) &amp;= -\lambda X \\
{-log_e(1 - U) \over \lambda} &amp;= X
\end{align}
\]</p>
<p>As a result, if \( U \sim U(0,1) \) then \( -log_e(1 - U) / \lambda \sim exp(\lambda) \). Notice that we can also replace \( 1 - U \) with \( U \) as \( 1 - U \sim U(0,1) \) as well. This means that \(-log_e(U) / \lambda \sim exp(\lambda) \).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="acceptance-rejection-ar-method"><a class="header" href="#acceptance-rejection-ar-method">Acceptance-Rejection (AR) Method</a></h1>
<p>If the c.d.f \( F(x) \) cannot be inverted then we can sometimes use the p.d.f \( f(x) \) instead.</p>
<p>Firstly, find a function \( h(x) \) which <strong>dominates</strong> \( f(x) \), meaning \( h(x) \ge f(x) \) for all \( x \). Then generate a density function \( g(x) \) by &quot;normalising&quot; \( h(x) \) so that the area under \( g(x) \) is equal to \( 1 \):</p>
<p>\[
\int_x h(x) dx = c \implies g(x) = {h(x) \over c}
\]</p>
<p>Thus, the c.d.f is given by:</p>
<p>\[
\begin{align}
G(x) &amp;= \int_{-\infty}^{x} g(t)dt \\
&amp;= \int_{-\infty}^{x} {h(t) \over c} dt
\end{align}
\]</p>
<p>\( g(x) \) and/or \( G(x) \) need to be easy to sample for this method to work.</p>
<p>An alternative method is starting with some p.d.f \( g(x) \) and scaling it by a factor \( c \) to get a function \( h(x) \) which dominates \( f(x) \):</p>
<p>\[
\begin{align}
c &amp;= c \int_x g(x) dx \\
&amp;= \int_x h(x) dx
\end{align}
\]</p>
<h2 id="ar-algorithm"><a class="header" href="#ar-algorithm">AR Algorithm</a></h2>
<ol>
<li>Let \( X \) be a sample from \( g(x) \) or \( G(x) \).</li>
<li>Let \( U \) be a sample from the \( U(0, 1) \) distribution and let \( Y = U * h(X) \).</li>
<li>If \( Y \le f(X) \) then <strong>accept</strong> \( X \), otherwise <strong>reject</strong> it and start over.</li>
</ol>
<p>Note that \( Y \le f(x) \) can also be rewritten as:</p>
<p>\[
U \le {f(X) \over h(X)} = {f(X) \over c * g(X)}
\]</p>
<p><img src="distribution-sampling/./images/acceptance-rejection-sample-graphs.png" alt="" /></p>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<p>Take a standard &quot;half-normal&quot; distribution (the standard normal distribution, but cut in half by taking only positive values of \( x \)):</p>
<p>\[
f(x) = {2 \over \sqrt{2 \pi}} e^{-x^2/2}
\]</p>
<p>Note that the \( 2 \) on top of the fraction is because a half normal has the area of \( 1 / 2 \), so it's multiplied by \( 2 \) to make it a valid p.d.f.</p>
<p>Now take an arbitrary p.d.f, say \( g(x) = e^{x} \) (an exponential with parameter 1) as it is easy to sample. To calculate \( h(x) = c * g(x) \) such that it dominates \( f(x) \), \( c \) needs to be computed. Firstly find:</p>
<p>\[
\max_x {f(x) \over g(x)}
\]</p>
<p>by finding:</p>
<p>\[
\begin{align}
c &amp;= \max_{x \ge 0} {{2 \over \sqrt{2 \pi}} e^{-x^2 / 2} \over e^{-x}} \\
&amp;= \max_{x \ge 0} \sqrt{2 \over \pi} e^{x - x^2 / 2}
\end{align}
\]</p>
<p>Through differentiation, the maximum of this equation is when \( x = 1 \) so:</p>
<p>\[
\begin{align}
c &amp;= \sqrt{2 \over \pi} e^{1/2} \\
&amp;= \sqrt{2e \over \pi}
\end{align}
\]</p>
<p>and from this we get:</p>
<p>\[
h(x) = \sqrt{2e \over \pi} e^{-x} \\
{f(x) \over h(x)} = e^{-{1 \over 2}(x - 1)^2}
\]</p>
<p><img src="distribution-sampling/./images/half-normal.png" alt="" /></p>
<p>Using this, we can sample \( X \) from \( -\ln(1 - U_1) \) (found using the inverse transform method applied to the exponential distribution with parameter \( 1 \)) and accept \( X \) iff:</p>
<p>\[
U_2 \le {f(X) \over h(X)} = e^{-{1 \over 2}(X-1)^2}
\]</p>
<p>where \( U_1,U_2 \sim U(0, 1) \).</p>
<h2 id="special-case"><a class="header" href="#special-case">Special Case</a></h2>
<p>If \( a \le x \le b \) then we can bound \( f(x) \) within a rectangle using \( U(a,b) \). Let \( g(x) = {1 \over (b-a)} \) and \( h(x) = \max_x f(x) = m \). Then, sample \( X \) from \( U_1 * (b - a) + a \) and accept \( X \) iff:</p>
<p>\[
U_2 \le {f(X) \over h(X)} = {f(X) \over m}
\]</p>
<p>where \( U_1, U_2 \sim U(0,1) \).</p>
<p><img src="distribution-sampling/./images/bounded-graph.png" alt="" /></p>
<h3 id="proof-1"><a class="header" href="#proof-1">Proof</a></h3>
<p>To prove this, we need to show that the values of \( X \) that are accepted have a c.d.f equal to \( F \):</p>
<p>\[
P \left( X \le x \mid U \le {f(X) \over h(X)} \right) = F(x)
\]</p>
<p>This is done by the following proof (remember that \( X \) has the density function \( g(X) \) and \( h(x) = c * g(x) \)):</p>
<p>\[
\begin{align}
P \left( X \le x \mid U \le {f(X) \over h(X)} \right) &amp;= {P \left( U \le {f(X) \over c * g(X)} \land X \le x \right) \over P \left( U \le {f(X) \over c * g(X)} \right)} \\
&amp;= {\int_0^x P \left( U \le {f(X) \over c * g(X)} \mid X = y \le x \right) g(y) dy \over {1 \over c} } \\
&amp;= c \int_0^x {f(y) \over c * g(y)} g(y) dy \\
&amp;= \int_0^x f(y) dy \\
&amp;= F(x)
\end{align}
\]</p>
<h2 id="efficiency"><a class="header" href="#efficiency">Efficiency</a></h2>
<p>The efficiency of a particular dominating function depends on the number of rejections \( R \) before accepting a value of \( X \). The probability \( p \) of accepting a value of \( X \) in any single experiment is equal to the ratio of the areas of the two functions, \( f(x) \) and \( h(x) \). This is equal to \( 1 \over c \), and since each experiment is independent then this means \( R \) is <strong>geometrically</strong> distributed:</p>
<p>\[
P(R = r) = p(1 - p)^r
\]</p>
<p>so the expected number of rejections is given by:</p>
<p>\[
\begin{align}
E(R) &amp;= {1 - p \over p} \\
&amp;= c - 1
\end{align}
\]</p>
<p>and since the next iteration should give be accepted, this gives the average number of iterations as simply \( c \). This value can be used to approximate the number of random numbers needed to sample a distribution. For example, in the half-normal example:</p>
<p>\[
c = \sqrt{2e \over \pi} = 1.315
\]</p>
<p>and each iteration needs two random \( U(0, 1) \) samples, so that is an average \( 2 * 1.315 = 2.63 \) samples per sample of \( X \).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="convolution-method"><a class="header" href="#convolution-method">Convolution Method</a></h1>
<p>A distribution is a <strong>convolution</strong> of other distributions is it is the sum of their individual random variables. This sum can be weighted.</p>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<p>An \( Erlang(k, \theta) \) random variable is defined as the sum of \( k \) random variables, each following an \( exp(\theta) \) distribution.</p>
<p>The expected value is given by:</p>
<p>\[
E(X) = {1 \over \theta} + {1 \over \theta} + \dots + {1 \over \theta} = {k \over \theta}
\]</p>
<p>Therefore, we can generate samples for an \( Erlang(k, \theta) \) random variable using the inverse transform technique on the exponential distribution. If \( X_i \sim exp(\theta) \):</p>
<p>\[
X = \sum_{i = 1}^k X_i \sim Erlang(k, \theta)
\]</p>
<p>Additionally, if \( U_i \sim U(0, 1) \) then \( X_i \) is sampled using:</p>
<p>\[
-\ln{U_i \over \theta}
\]</p>
<p>Calculating the logarithm of a value can be quite computationally expensive, so we can manipulate the result from a summation to a product:</p>
<p>\[
\begin{align}
X &amp;= \sum_{i = 1}^k - {\ln{U_i} \over \theta} \\
&amp;= - {1 \over \theta} \ln \prod_{i = 1}^k U_i
\end{align}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sampling-discrete-distributions"><a class="header" href="#sampling-discrete-distributions">Sampling Discrete Distributions</a></h1>
<p>Once again, we can apply the inverse transform method by finding the inverse of the c.d.f.</p>
<p>Take an arbitrary random variable \( X \); its c.d.f will be a &quot;step function&quot;:</p>
<pre><code>
                            F(x)
                               ^
  *---*--------*------*   1.00 |               +---+
  | x | P(X=x) | F(x) |   0.81 |           +---+   |
  *---*--------*------*   0.66 |       +---+   |   |
  | 0 |  0.15  | 0.15 |        |       |   |   |   |
  | 1 |  0.24  | 0.39 |   0.39 |   +---+   |   |   |
  | 2 |  0.22  | 0.61 |        |   |   |   |   |   |
  | 3 |  0.20  | 0.81 |   0.15 +---+   |   |   |   |
  | 4 |  0.19  | 1.00 |        |   |   |   |   |   |
  *---*--------*------*        +---+---+---+---+---+---&gt;
                                 0   1   2   3   4     x

</code></pre>
<p>Thus, take a uniform random variable \( U \sim U(0, 1) \), then the inverse transform method gives us:</p>
<p>\[
X = \min \{ x : F(x) \ge U \}
\]</p>
<p>In practice, this can be done by simply looking up the which value in the c.d.f is greater than \( U \):</p>
<pre><code>Sample U from U(0, 1)

For each x:
  If U &lt;= F(x):
    Return x
</code></pre>
<h2 id="sampling-in-constant-time-alias-method"><a class="header" href="#sampling-in-constant-time-alias-method">Sampling in Constant Time (Alias Method)</a></h2>
<p>The previous solution runs in \( O(n) \), but it is possible to sample the distribution in \( O(1) \). The idea is to convert the p.d.f, which looks like this</p>
<pre><code>  f(x) ^
       |   +---+
       |   |   |   +---+
       |   |   +---+   |
       |   |   |   |   +---+
       +---+   |   |   |   |
       |   |   |   |   |   |
       |   |   |   |   |   |
       +---+---+---+---+---+--&gt;
         0   1   2   3   4    x
</code></pre>
<p>into something that looks like this:</p>
<pre><code>
       ^
       |
       |
   1/n +---+---+---+---+---+
       |   |   |   |   +---+
       +---+   |   |   |   |
       |   |   |   |   |   |
       |   |   |   |   |   |
       +---+---+---+---+---+--&gt;
         0   1   2   3   4    x
</code></pre>
<p>where \( 1 \over n \) is the average height of each column. Note that in this diagram, each &quot;block&quot; no longer corresponds to the horizontal coordinate of the graph.</p>
<h3 id="construction-algorithm"><a class="header" href="#construction-algorithm">Construction Algorithm</a></h3>
<p>This rectangle can be constructed by breaking up columns that exist above the average height \( m \) into smaller chunks, then putting all of these smaller chunks back together.</p>
<pre><code>Caluclate m
Let smaller be the set of tuples (x, p) where p = p(x) and p &lt;= m
Let larger be the set of tuples (x, p) where p = p(x) and p &gt; m
Let result be an empty list of tuples (x1, x2, alias)

For each column in the output result:
  Pop (x1, p1) from the smaller set
  Pop (x2, p2) from the larger set
  Let (x3, p3) = (x2, p2 - p1)
  Let result[column] = (p1, x1, x2)

  If p3 &lt;= m:
    Push (x3, p3) to smaller
  Else:
    Push (x3, p3) to larger
</code></pre>
<p>Note the algorithm above is simplified just to convey the general idea (i.e. it doesn't handle the case where \( p(x) = {1 \over n} \)).</p>
<h3 id="sampling-algorithm"><a class="header" href="#sampling-algorithm">Sampling Algorithm</a></h3>
<p>To sample this new graph, two uniform random numbers will be needed:</p>
<ol>
<li>\( U_1 \sim U(0,4) \) is a <em>discrete</em> random variable which will pick which column is to be sampled.</li>
<li>\( U_2 \sim U(0, m) \) is a <em>continuous</em> random variable which will decide which chunk of the column is chosen.</li>
</ol>
<p>Then, using the list <code>result</code> from the construction algorithm:</p>
<pre><code>Let u1 be a sample from U1
Let u2 be a sample from U2
Let (x1, x2, alias) = result[u1]

If u2 &lt;= alias:
  Return x1
Else:
  Return x2
</code></pre>
<p>It is obvious that this algorithm will run in \( O(1) \) if the sampling methods for \( U_1, U_2 \) run in \( O(1) \) (which they do).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="continuous-time-markov-chains-ctmcss"><a class="header" href="#continuous-time-markov-chains-ctmcss">Continuous-Time Markov Chains CTMCSs</a></h1>
<p><strong>Continuous-Time Markov Chains</strong> (also known as <strong>Markov Processes (MPs)</strong> ) are a form of stochastic processes which is defined by a set of states \( S \) and a square matrix known as a <strong>transition rate matrix</strong> or <strong>generator matrix</strong> \( \boldsymbol{Q} \) with dimensions \( \lvert S \rvert \times \lvert S \rvert \). For example, a CTMC with \( 3 \) states will have the following generator matrix:</p>
<p>\[
\begin{bmatrix}
-(q_{1,2} + q_{1,3}) &amp; q_{1,2} &amp; q_{1,3} \\
q_{2,1} &amp; -(q_{2,1} + q_{2,3}) &amp; q_{2,3} \\
q_{3,1} &amp; q_{3,2} &amp; -(q_{3,1} + q_{3,2}) \\
\end{bmatrix}
\]</p>
<p>where \( q_{i, \, j} \) is the <strong>transition-rate</strong> from state \( i \) to state \( j \), \( 1 \le i, j \le \lvert S \rvert \) (more on generator matricies later).</p>
<p>In a CTMC there are no self-loops as they don't affect the transitions out of the system (remember that Poisson Processes are memoryless). This means that the diagonal terms \( q_{i,i} \) are effectively unused, and so they can be used for something else. By convention, the negative sum of each row is stored in the diagonals:</p>
<p>\[
q_{i,i} = - \sum_{j \in S, \, j \ne i} q_{i, \, j}
\]</p>
<p>This will be useful later.</p>
<h2 id="state-holding-times"><a class="header" href="#state-holding-times">State Holding Times</a></h2>
<p>Since \( q_{i, \, j} \) is the rate parameter of an exponentially distributed random variable, if \( X_{i, \, j} \sim exp(q_{i, \, j}) \) then we get the following:</p>
<p>\[
\begin{align}
F_{i,\,j}(x) &amp;= 1 - e^{- q_{i, \, j} x} \\
f_{i,\,j}(x) &amp;= q_{i, \, j} e^{- q_{i, \, j} x}
\end{align}
\]</p>
<p>where \( x \ge 0 \) and \( q_{i, \, j} \ge 0 \). As a result, if there are multiple transitions out of a state, then they will &quot;race&quot; with each other: the first event to trigger will be the state transition taken. Thus, the <strong>state holding time</strong> is the <strong>minimum</strong> of the samples of each exponentially distributed random variable out of the current state:</p>
<p>\[
\begin{align}
P \left( \left( \, \min_{1 \le j \le n} X_{i,\,j} \right) \le x \right) &amp;= 1 - P \left( X_1 \gt x \land \dots \land X_n \gt x \right) \\
&amp;= 1 - \prod_{j = 1}^n e^{-r_{i, \, j} x} \\
&amp;= 1 - e^{-(r_{i,1} + \dots + r_{i,n}) x} \\
&amp;= 1 - e^{q_{i,i} x}
\end{align}
\]</p>
<p>Remember that the minimum of a set of exponentially distributed random variables is also an exponentially distributed random variable (see <a href="poisson-processes/properties-of-the-exponential-distribution.html">here</a>).</p>
<p>Therefore, the state holding time can be modelled by an exponentially distributed random variable with rate parameter \( q_{i, i} \).</p>
<h2 id="the-markov-property"><a class="header" href="#the-markov-property">The Markov Property</a></h2>
<p>Since the state holding time is exponentially distributed, it means that it is also memoryless. As a result, the next transition in the system is determined only by the current state. If \( S(t) \in S \) is defined as the state of the process at time \( t \), then the <strong>Markov Property</strong> for \( t_1 \lt t_2 \lt \dots \lt t_n \) is defined as:</p>
<p>\[
P \left( S( t_n ) = s_n \mid S(t_{n-1}) = s_{n-1}, \dots , S(t_1) = s_1 \right) = P \left( S(t_n) = s_n \mid S(t_{n-1}) = s_{n-1} \right)
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="steady-state-solution-of-a-markov-process"><a class="header" href="#steady-state-solution-of-a-markov-process">Steady-state Solution of a Markov Process</a></h1>
<p>Let \( p_s(t) = P(S(t) = s) \) be the probability that at time \( t \) the current state of the process is \( s \in S \). To find the <strong>steady-state</strong> (or <strong>equilibrium</strong>) solution, we need to derive a set of linear equations that will define the convergent solution for \( p_s(t) \) as \( t \rightarrow \infty \) (also known as \( p_s \)).</p>
<p>There are two approaches:</p>
<ul>
<li><strong>Numerical</strong>: solve the system of linear equations to calculate the steady-state probabilities.</li>
<li><strong>Analytical</strong>: for certain systems, it is possible to spot direct solutions to the linear system, which is preferable.</li>
</ul>
<p>Once we have the steady-state probabilities of \( p_s, s \in S\), we can use it to caluclate other performance measures of the system. This can also be done numerically or analytically.</p>
<h2 id="linear-equations"><a class="header" href="#linear-equations">Linear Equations</a></h2>
<p>Given a <strong>irreducible</strong> (also known as <em>ergodic</em>) CTMC, meaning every state can reach every other state, with a finite or countably infinite number of states in \( S \), then at equilibrium the <strong>probability flux</strong> of leaving any state \( s \in S \) should be equal to the <strong>probability flux</strong> coming into that state:</p>
<p>\[
p_i \sum_{j \in S, \, j \ne i} q_{i, \, j} = \sum_{j \in S, \, j \ne i} p_j q_{j, \, i}
\]</p>
<p>These are known as the (Global) <strong>Balance Equations</strong>. The left-hand side is equal to the probability of leaving the state, and the right-hand side is equal to the probability of entering the state. The derivation can be found here <a href="continuous-time-markov-chains//continuous-time-markov-chains/steady-state-solution-of-a-markov-process/derivation-of-balance-equations.html">here</a>.</p>
<p>At equilibrium, a <em>finite</em> CTMC with a finite generator matrix will statisfy the following equation:</p>
<p>\[
\vec{p} \, \boldsymbol{Q} = \boldsymbol{0}
\]</p>
<p>where \( \vec{p} = \begin{bmatrix} p_1 &amp; p_2 &amp; \dots &amp; p_n \end{bmatrix} \).</p>
<h3 id="theorem"><a class="header" href="#theorem">Theorem</a></h3>
<p>If a CTMC is finite and irreducible, then there exists a limiting distribution:</p>
<p>\[
\vec{p} = \lim_{t \rightarrow \infty} \vec{p}(t)
\]</p>
<h2 id="solving-balance-equations"><a class="header" href="#solving-balance-equations">Solving Balance Equations</a></h2>
<p>Since an irreducible CTMC will have a singular generator matrix (every row sums to \( 0 \)), no inverse matrix will exist. This means that there isn't a unique solution. However, by encoding the normalising condition:</p>
<p>\[
\sum_{s \in S} p_s = 1
\]</p>
<p>into \( \boldsymbol{Q} \), then it will become non-singular, so a unique solution for \( \vec{p} \) can be found.</p>
<p>To do this, pick a random column \( c, \, 1 \le c \le n \) and set all of its values to \( 1 \):</p>
<p>\[
\begin{bmatrix}
q_{1,1} &amp; q_{1,2} &amp; \dots &amp; q_{1,c-1} &amp; 1 &amp; q_{1, c+1} &amp; \dots &amp; q_{1, n} \\
q_{2,1} &amp; q_{2,2} &amp; \dots &amp; q_{2,c-1} &amp; 1 &amp; q_{2, c+1} &amp; \dots &amp; q_{2, n} \\
\dots \\
q_{n,1} &amp; q_{n,2} &amp; \dots &amp; q_{n,c-1} &amp; 1 &amp; q_{n, c+1} &amp; \dots &amp; q_{n, n}
\end{bmatrix} = \begin{bmatrix}
0 &amp; 0 &amp; \dots &amp; 0 &amp; 1 &amp; 0 &amp; \dots &amp; 0
\end{bmatrix}
\
\]</p>
<p>where the output vector is a vector with \( n - 1 \) zeros and a single \( 1 \) in column \( c \).</p>
<h3 id="theorem-1"><a class="header" href="#theorem-1">Theorem</a></h3>
<p>An irreducible CTMC with \( n \) states will have a generator matrix with rank \( n-1 \).</p>
<h3 id="corollary"><a class="header" href="#corollary">Corollary</a></h3>
<p>Given an irreducible CTMC with \( n \) states, the normalised generator matrix with one column set all to \( 1 \) will be rank \( n \) and as a result it will be non-singular and invertible.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="derivation-of-balance-equations"><a class="header" href="#derivation-of-balance-equations">Derivation of Balance Equations</a></h1>
<p>Assume the CTMC has a finite or countably infinite number of states in \( S \). Given some rate parameter \( r \), the probability that a specific number of events \( N \) occur in some time interval \( \Delta \) is given by:</p>
<p>\[
P(N = n) = {({r \Delta t})^n e^{-r \Delta t} \over n!}
\]</p>
<p>as \( \Delta t \) is Poisson distributed. Also remember that the expansion of \( e^x \) is:</p>
<p>\[
e^x = 1 + x + {x^2 \over 2!} + {x^3 \over 3!} + \dots
\]</p>
<p>Then the probability that there are no events be rewritten as:</p>
<p>\[
\begin{align}
P(N = 0) &amp;= {({r \Delta t})^0 e^{-r \Delta t} \over 0!} \\
&amp;= e^{-r \Delta t} \\
&amp;= 1 - r \Delta t + {(r \Delta t)^2 \over 2!} - {(r \Delta t)^3 \over 3!} + \dots \\
&amp;= 1 - r \Delta t + o(\Delta t)
\end{align}
\]</p>
<p>where \( o(\Delta t) \) represents a summation of higher orders of \( \Delta t \) such that:</p>
<p>\[
\lim_{\Delta t \rightarrow 0} {o(\Delta t) \over \Delta t} = 0
\]</p>
<p>Similarly, the probability that there is exactly one event that occurs is:</p>
<p>\[
\begin{align}
P(N = 1) &amp;= (r \Delta t) e^{-r \Delta t} \\
&amp;= r \Delta t + o(\Delta t)
\end{align}
\]</p>
<p>and the probability that more than one event occurs is:</p>
<p>\[
P(N \gt 1) = o(\Delta t)
\]</p>
<p>Applying this to the CTMC transition rates, if \( X_{i, \, j} \sim exp(q_{i, \, j}), i \ne j \), the probability of there being no state transitions out of state \( i \) in a time period \( \Delta t \) is equal to:</p>
<p>\[
\prod_{j \in S, \, j \ne i} \left( 1 - q_{i, \, j} \Delta t + o(\Delta t) \right) = 1 - \sum_{j \in S, \, j \ne i} q_{i, \, j} \Delta t + o(\Delta t)
\]</p>
<p>and therefore the probability of there being exactly one transition is \( q_{i, \, j} \Delta t + o(\Delta t) \) and the probability of there being more than one transition is \( o(\Delta t) \).</p>
<p>Combining these equations together, the probability of being in state \( i \) at time \( t + \Delta t \) is given by the sum of:</p>
<ul>
<li>The probability of being in state \( i \) and no transitions occuring.</li>
<li>The sum of the probabilities of being in state \( j \) where \( i \ne j \) and there being one transition from state \( j \) to state \( i \).</li>
<li>The sum of the probabilities of being in some arbitrary state and there being \( 2 \) or more transitions that end up in state \( i \).</li>
</ul>
<p>Therefore:</p>
<p>\[
\begin{align}
p_i(t + \Delta t) &amp;= p_i(t) \left( 1 - \sum_{j \in S, \, j \ne i} q_{i, \, j} \Delta t \right) \\
&amp; \quad + \sum_{j \in S, \, j \ne i} p_j(t) q_{j, i} \Delta t \\
&amp; \quad + o(\Delta t)
\end{align}
\]</p>
<p>This can then be rearranged to get:</p>
<p>\[
{p_i(t + \Delta t) - p_i(t) \over \Delta t} = -p_i(t) \sum_{j \in S, \, j \ne i} q_{i, \, j} + \sum_{j \in S, \, j \ne i} p_j(t) q_{j, i} + {o(\Delta t) \over \Delta t}
\]</p>
<p>Recall that this is the equation for differentiation from first principals. Thus, in the limit \( \Delta t \rightarrow 0 \):</p>
<p>\[
{dp_i(t) \over dt} = -p_i(t) \sum_{j \in S, \, j \ne i} q_{i, \, j} + \sum_{j \in S, \, j \ne i} p_j(t) q_{j, i}
\]</p>
<p>If for all states \( i \in S \) there exists some limit \( p_i \) such that as \( t \rightarrow \infty, \, p_i(t) \rightarrow p_i \) (i.e. there exists a steady state probability for all states) then:</p>
<p>\[
\lim_{t \rightarrow \infty} {dp_i(t) \over dt} = 0
\]</p>
<p>which means:</p>
<p>\[
0 = -p_i \sum_{j \in S, \, j \ne i} q_{i, \, j} + \sum_{j \in S, \, j \ne i} p_j q_{j, i} \\
\]</p>
<p>so finally we get the <strong>balance equations</strong>:</p>
<p>\[
p_i \sum_{j \in S, \, j \ne i} q_{i, \, j} = \sum_{j \in S, \, j \ne i} p_j q_{j, i}
\]</p>
<h3 id="vectormatrix-form"><a class="header" href="#vectormatrix-form">Vector/Matrix Form</a></h3>
<p>To go a step futher, remember that the diagonal entries to the generator matrix are equal to the negative sum of each row. As a result, we can rewrite the equation above:</p>
<p>\[
\begin{align}
p_i \sum_{j \in S, \, j \ne i} q_{i, \, j} &amp;= \sum_{j \in S, \, j \ne i} p_j q_{j, i} \\
-p_i q_{i,i} &amp;= \sum_{j \in S, \, j \ne i} p_j q_{j, i} \\
0 &amp;= p_i q_{i,i} + \sum_{j \in S, \, j \ne i} p_j q_{j, i} \\
0 &amp;= \sum_{j \in S} p_j q_{j, i}
\end{align}
\]</p>
<p>and if we let \( \vec{p} = \begin{bmatrix} p_1 &amp; p_2 &amp; \dots &amp; p_n \end{bmatrix} \) then we can then rewrite the balance equations as the following:</p>
<p>\[
\begin{align}
\vec{p} \boldsymbol{Q} = \boldsymbol{0}
\end{align}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="analytical-modelling-queueing-systems"><a class="header" href="#analytical-modelling-queueing-systems">Analytical Modelling: Queueing Systems</a></h1>
<p><strong>Analytical methods</strong> are used to analyze models mathematically and probabilistically.</p>
<p>There are three main approaches/methods to analyze a system:</p>
<ol>
<li>Measurement approach.</li>
<li>Simulation approach.</li>
<li>Analytical modelling.</li>
</ol>
<h3 id="measurement-approach"><a class="header" href="#measurement-approach">Measurement Approach</a></h3>
<p>Pros:</p>
<ul>
<li>Simple to do.</li>
<li>Collected data is the ground truth (not relying on any assumptions).</li>
<li>No knowledge of the system is required, and can be applied to any system.</li>
</ul>
<p>Cons:</p>
<ul>
<li>Typically slow.</li>
<li>Rare events may not occur during the tests.</li>
<li>Takes some effort to automate the process.</li>
<li>Collected results can be affected by &quot;noise&quot;.</li>
</ul>
<h3 id="simulation-approach"><a class="header" href="#simulation-approach">Simulation Approach</a></h3>
<p>Pros:</p>
<ul>
<li>Easy to learn.</li>
<li>Easy to produce/reproduce rare events and assess their impact.</li>
<li>Fast enough for repeated evaluations (can typically run in minutes to hours).</li>
</ul>
<p>Cons:</p>
<ul>
<li>Modelling skills are require</li>
<li>Knowledge about the system is required to model it.</li>
<li>Simulation software can have (many) bugs.</li>
</ul>
<h3 id="analytical-modelling"><a class="header" href="#analytical-modelling">Analytical Modelling</a></h3>
<p>Pros:</p>
<ul>
<li>Fast (typically within seconds to minutes).</li>
<li>Helpful for optimisation-based search.</li>
<li>Helpful for machine learning and probabilistic inference.</li>
<li>Is typically the main method used for formally proving properties of an algorithm or of system behavior.</li>
</ul>
<p>Cons:</p>
<ul>
<li>Strong modelling skills are required.</li>
<li>Knowledge about the system is required to model it.</li>
<li>Works better on simpler systems (e.g. single resources) compared to complex systems.</li>
</ul>
<p>Measurement, simulation, and analytical methods are complementary and should be used together: they aren't competing alternatives.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="markovian-queueing-theory"><a class="header" href="#markovian-queueing-theory">Markovian Queueing Theory</a></h1>
<p>Some Markov Processes (CTMCs) have direct analytical solutions to balance equations:</p>
<p>\[
\vec{p} \boldsymbol{Q} = \boldsymbol{0}
\]</p>
<p>and these class of models are known as <strong>Marvokian Queues</strong>.</p>
<p>A <strong>queueing system</strong> is a single-queue system characterised by:</p>
<ul>
<li>\( A \): The arrival process</li>
<li>\( S \): The service time distribution</li>
<li>\( c \): The number of servers</li>
<li>\( k \): The capacity of the queue buffer (default is \( \infty \))</li>
<li>\( N \): The capacity of the job source (default is \( \infty \))</li>
<li>\( d \): The scheduling discipline (default FCFS)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kendalls-notation"><a class="header" href="#kendalls-notation">Kendall's Notation</a></h1>
<p><strong>Kendall's notatation</strong> \( A/S/c/k/N-d \) is used to describe a system with these parameters.</p>
<p>The common abbreviations for the arrival process \( A \) and the service time distribution \( S \) are:</p>
<ul>
<li>\( M \): &quot;Memoryless&quot;</li>
<li>\( D \): &quot;Deterministic&quot; (constant)</li>
<li>\( E_j \): Erlang-j distrRbuted (a sum of \( j \) exponential random variables)</li>
<li>\( G \): General (arbitrary)</li>
<li>\( GI \): General independent (no trends, bursts, periodicities, etc)</li>
</ul>
<p>The common abbreviations for the discipline \( d \) are:</p>
<ul>
<li>FCFS: First-Come-First-Server (a FIFO buffer)</li>
<li>LCFS: Last-Come-First-Server (a LIFO buffer)</li>
<li>PS: Processor Sharing (equivilant to round robin as the time slice/quantum tends to 0, with zero context switching time)</li>
<li>IS: Infinite Server (i.e. just a delay, no queue)</li>
<li>SIRO: Service-in-Random-Order</li>
</ul>
<p>For example, an \( M/M/1 \) queue has:</p>
<ul>
<li>A Poisson arrival process (inter-arrival times are exponentially distributed, and so they are <em>memoryless</em>)</li>
<li>Exponentially distributed (again, <em>memoryless</em>) service times</li>
<li>A single server</li>
<li>First-come, first-served scheduling</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the--mm1--queue"><a class="header" href="#the--mm1--queue">The \( M/M/1 \) Queue</a></h1>
<p>This is the simplest Markovian queue, and it can be modelled by a CTMC with the following state transition graph:</p>
<p><img src="analytical-modelling-queueing-systems/./images/mm1-state-transitions.png" alt="" /></p>
<p>This CTMC has the following balance equations:</p>
<p>\[
\begin{align}
\lambda p_0 &amp;= \mu p_1 \\
(\lambda + \mu) p_n &amp;= \lambda p_{n-1} + \mu p_{n+1}, \quad n \gt 0
\end{align}
\]</p>
<p>where the top equation is for the edge case state \( 0 \), and the bottom equation is for every other state with two states either side of it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="steady-state-distribution"><a class="header" href="#steady-state-distribution">Steady-state Distribution</a></h1>
<p>A &quot;analytical&quot;, or &quot;closed-form&quot;, solution can be found by inspection. For state \( 1 \) we get:</p>
<p>\[
\begin{align}
\mu p_1 &amp;= \lambda p_0 \\
p_1 &amp;= {\lambda \over \mu} p_0 \\
&amp;= \rho p_0
\end{align}
\]</p>
<p>where \( \rho = {\lambda \over \mu} \). This result can be used to solve state \( 2 \):</p>
<p>\[
\begin{align}
(\lambda + \mu) p_1 &amp;= \lambda p_0 + \mu p_2 \\
\lambda p_1 + \mu p_1 &amp;= \mu p_1 + \mu p_2 \\
\lambda p_1 &amp;= \mu p_2 \\
p_2 &amp;= \rho p_1 \\
&amp;= \rho^2 p_0 \\
\end{align}
\]</p>
<p>Remember that \( \lambda p_0 = \mu p_1 \). We can see that this is following a trend, so for any state \( n, 0 \le n \) we get:</p>
<p>\[
p_n = \rho^n p_0
\]</p>
<p>which turns out to be the exact solution. This can be proven formally by using induction, or by showing that it satisfies the balance equations.</p>
<h2 id="finding--p_0-"><a class="header" href="#finding--p_0-">Finding \( p_0 \)</a></h2>
<p>To find \( p_0 \), we can use the normalising equation:</p>
<p>\[
\sum_{n = 0}^{\infty} p_n = \sum_{n = 0}^{\infty} \rho^n p_0 = 1
\]</p>
<p>which is rearranged to:</p>
<p>\[
p_0 = \left[ \, \sum_{n = 0}^{\infty} \rho^n \right]^{-1} = 1 - \rho
\]</p>
<p>Note that this sum only converges if \( \rho \lt 1 \) which is true only when \( \lambda \lt \mu \), hence the a system with \( \lambda = \mu \) has no solution and is <strong>unstable</strong>.</p>
<h2 id="finding--p_n-"><a class="header" href="#finding--p_n-">Finding \( p_n \)</a></h2>
<p>By substituting the result \( p_0 = 1 - \rho \) back into the equation for \( p_n \), we get:</p>
<p>\[
p_n = (1 - \rho) \rho^n, \quad n \ge 0
\]</p>
<p>which means that the probability of being in a state \( n \) geometrically decays as \( n \) increases:</p>
<p><img src="analytical-modelling-queueing-systems/the-mm1-queue/./images/geometric-decay.png" alt="" /></p>
<p>Note in this graph \( \rho = 0.8 \).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-indicies"><a class="header" href="#performance-indicies">Performance Indicies</a></h1>
<p>Using the previous results, we can calculate some performance indicies.</p>
<h3 id="throughtput--x-"><a class="header" href="#throughtput--x-">Throughtput \( X \)</a></h3>
<p>When in state \( 0 \) the throughput is \( 0 \), and when in state \( n \gt 0 \) the throughput is \( \mu \).</p>
<p>\[
\begin{align}
X &amp;= p_0 * 0 + (1 - p_0) * \mu \\
&amp;= \rho \mu \\
&amp;= \lambda
\end{align}
\]</p>
<h3 id="server-utilisation--u-"><a class="header" href="#server-utilisation--u-">Server Utilisation \( U \)</a></h3>
<p>The server is idle when \( n = 0 \), and is busy otherwise.</p>
<p>\[
\begin{align}
U &amp;= 1 - p_0 \\
&amp;= \rho
\end{align}
\]</p>
<h3 id="mean-queue-length--n-"><a class="header" href="#mean-queue-length--n-">Mean Queue-length \( N \)</a></h3>
<p>The population is a geometrically distributed random variable with parameter \( \rho \) (see <a href="analytical-modelling-queueing-systems/the-mm1-queue/performance-indicies.html#finding--p_n-">here</a>), so the mean population/queue-length is:</p>
<p>\[
\begin{align}
N &amp;= \sum_{n=0}^{\infty} n p_n \\
&amp;= {\rho \over 1 - \rho} \\
\end{align}
\]</p>
<p><img src="analytical-modelling-queueing-systems/the-mm1-queue/./images/geometric-distribution-mean-graph.png" alt="" /></p>
<p>Notice how this graph has an asymptote at \( \rho = 1 \).</p>
<h3 id="mean-response-time--r-"><a class="header" href="#mean-response-time--r-">Mean Response Time \( R \)</a></h3>
<p>Remember that the response time is equal to the mean time that a job spends inside the system (queueing time + service time). It can be found using <a href="analytical-modelling-queueing-systems/the-mm1-queue//operational-laws/littles-law.html">Little's Law</a>:</p>
<p>\[
\begin{align}
R &amp;= {N \over \lambda} \\
&amp;= {1 / \mu \over 1 - \rho} \\
&amp;= {1 \over \mu - \lambda}
\end{align}
\]</p>
<h3 id="mean-number-of-customers-waiting-to-be-served--n_q-"><a class="header" href="#mean-number-of-customers-waiting-to-be-served--n_q-">Mean Number Of Customers Waiting To Be Served \( N_Q \)</a></h3>
<p>On average, there are \( \rho \) customers being served. Therefore, the number of customers waiting to be served is equal to:</p>
<p>\[
\begin{align}
N_Q &amp;= N - \rho \\
&amp;= {\rho \over 1 - \rho} - \rho \\
&amp;= {\rho - (1 - \rho) \rho \over 1 - \rho} \\
&amp;= {\rho^2 \over 1 - \rho}
\end{align}
\]</p>
<h2 id="response-time-knee"><a class="header" href="#response-time-knee">Response Time &quot;Knee&quot;</a></h2>
<p><img src="analytical-modelling-queueing-systems/the-mm1-queue/./images/response-time-knee.png" alt="" /></p>
<p>The point \( \rho = 0.7 \) is conventionally regarded as the &quot;knee&quot; point of this curve. If a system is above this point, it is considered to be under <strong>heavy-load</strong>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="state-dependent-mm1-queue"><a class="header" href="#state-dependent-mm1-queue">State-dependent M/M/1 Queue</a></h1>
<p>Consider a queue where the arival and service rates depend on the size of the queue:</p>
<p><img src="analytical-modelling-queueing-systems/./images/state-dependent-mm1-queue-state-graph.png" alt="" /></p>
<p>This model has the following balance equations:</p>
<p>\[
\begin{align}
\lambda_0 p_0 &amp;= \mu p_1 \\
(\lambda_n + \mu_n) p_n &amp;= \lambda_{n-1} p_{n-1} + \mu_{n+1} p_{n+1}, \quad n \gt 0
\end{align}
\]</p>
<p>Using a similar derivation to the standard \( M/M/1 \) queue we get:</p>
<p>\[
\begin{align}
\mu_2 p_2 &amp;= \lambda_1 p_1 \\
p_2 &amp;= {\lambda_1 \over \mu_2} p_1 \\
&amp;= {\lambda_0 \lambda_1 \over \mu_1 \mu_2} p_0 \\
p_n &amp;= {\lambda_0 \dots \lambda_{n-1} \over \mu_1 \dots \mu_n} p_0 \\
&amp;= p_0 \prod_{k=0}^{n-1} {\lambda_k \over \mu_{k+1}}
\end{align}
\]</p>
<p>and applying the normalisation condition to calculate \( p_0 \):</p>
<p>\[
\begin{align}
\sum_{n=0}^\infty p_n &amp;= 1 \\
p_0 + \sum_{n=1}^\infty p_0 \prod_{k=0}^{n-1} {\lambda_k \over \mu_{k+1}} &amp;= 1 \\
p_0 + p_0 \sum_{n=1}^\infty \prod_{k=0}^{n-1} {\lambda_k \over \mu_{k+1}} &amp;= 1 \\
p_0 &amp;= {1 \over 1 + \sum_{n=1}^\infty \prod_{k=0}^{n-1} {\lambda_k \over \mu_{k+1}} }
\end{align}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multiple-parallel-servers--mmc--queue"><a class="header" href="#multiple-parallel-servers--mmc--queue">Multiple Parallel Servers \( M/M/c \) Queue</a></h1>
<p>Consider a system with the following:</p>
<ul>
<li>A Poisson arrival process.</li>
<li>Exponentially distributed service times.</li>
<li>\( c \) parallel servers.</li>
<li>First-come first-served scheduling.</li>
</ul>
<p><img src="analytical-modelling-queueing-systems/./images/parallel-servers-diagram.png" alt="" /></p>
<p>A queue like this can be modelled via the following CTMC:</p>
<p><img src="analytical-modelling-queueing-systems/./images/mmc-queue-ctmc.png" alt="" /></p>
<p>with a constant arrival rate \( \lambda_n = \lambda \) for all states \( n \ge 0 \) and a service rate that depends on the current queue population \( n \):</p>
<p>\[
\begin{align}
\mu_n &amp;= \min(n, c) * \mu \\
&amp;= \begin{cases}
n \mu &amp; 1 \le n \le c - 1 \\
c \mu &amp; n \ge c
\end{cases}
\end{align}
\]</p>
<p>This means that when the queue population is less than the number of servers \( c \), the service rate increases linearly with the number of jobs, and once it exceeds this number it behaves like an \( M/M/1 \) queue with a fixed service rate of \( c \mu \).</p>
<h2 id="balance-equations"><a class="header" href="#balance-equations">Balance Equations</a></h2>
<p>The balance equations for this model are the following:</p>
<p>\[
\begin{align}
\lambda p_0 &amp;= \mu p_1 \\
(\lambda + n \mu) p_n &amp;= \lambda p_{n-1} + (n + 1) \mu p_{n+1} &amp; 1 \le n \le c - 1 \\
(\lambda + c \mu) p_n &amp;= \lambda p_{n-1} + c \mu p_{n+1} &amp; n \ge c
\end{align}
\]</p>
<p>Applying the state-dependent \( M/M/1 \) formulas we get:</p>
<p>\[
\begin{align}
p_n &amp;= p_0 \prod_{i=1}^n {\lambda \over \mu_i} \\
&amp;= \begin{cases}
p_0 {\rho^n \over n!} &amp; 0 \le n \le c - 1 \\
p_0 {\rho^n \over c! c^{n-c}} &amp; n \ge c
\end{cases}
\end{align}
\]</p>
<p>where \( \rho = \lambda / \mu \). Note that the denominators come from \( \mu_n = \min(n,c) * \mu \), which means:</p>
<p>\[
\mu_1 = \mu \quad \mu_2 = 2 \mu \quad \dots \quad \mu_{c} = c \mu \quad \mu_{c+1} = c \mu \quad \dots
\]</p>
<p>so when they are multiplied together in a product we get:</p>
<p>\[
\begin{align}
\prod_{i=1}^n \mu_i &amp;= \left[ (1 \mu) (2 \mu) \dots ((c-1) \mu) (c \mu) \right] * \left[ (c \mu) \dots (c \mu) \right] \\
&amp;= (c! \mu^c) * (c^{n-c} \mu^{n-c}) \\
&amp;= c! c^{n-c} \mu_n
\end{align}
\]</p>
<p>Again, we can get \( p_0 \) by using the normalising condition:</p>
<p>\[
p_0 = {1 \over 1 + \sum_{n=1}^{c-1} {\rho^n \over n!} + {\rho^c \over (c-1)!(c-\rho)}}
\]</p>
<h2 id="performance-indicies-1"><a class="header" href="#performance-indicies-1">Performance Indicies</a></h2>
<h3 id="average-number-of-busy-servers--b-"><a class="header" href="#average-number-of-busy-servers--b-">Average Number of Busy Servers \( B \)</a></h3>
<p>The average number of busy servers \( B \) is given by:</p>
<p>\[
\begin{align}
B &amp;= \sum_{k=1}^{c-1} k p_k + c \sum_{k=c}^\infty p_k \\
&amp;= \dots \\
&amp;= \rho
\end{align}
\]</p>
<p>If the system is in a steady state, then the arrival rate \( \lambda \) should be equal to the average throughput \( B \mu \), so \( B \mu = \lambda \) which means that \(B = \lambda / \mu = \rho \) which satisfies the equation above.</p>
<h3 id="utilisation--u-"><a class="header" href="#utilisation--u-">Utilisation \( U \)</a></h3>
<p>The utilisation \( U \) is the fraction of servers that are being used, which is given by:</p>
<p>\[
U = {B \over c} = {\rho \over c}
\]</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="infinite-parallel-servers-mm-queue"><a class="header" href="#infinite-parallel-servers-mm-queue">Infinite Parallel Servers M/M/∞ Queue</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cheatsheet"><a class="header" href="#cheatsheet">Cheatsheet</a></h1>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<h3 id="scalars"><a class="header" href="#scalars">Scalars</a></h3>
<ul>
<li>\( A \): Number of arrivals.</li>
<li>\( C \): Number of completions.</li>
<li>\( T \): Amount of time (duration).</li>
<li>\( \lambda \): Arrival rate.</li>
<li>\( \lambda^{-1} \): Average inter-arrival time.</li>
<li>\( X \): Average throughput.</li>
<li>\( N \): (Average) number of jobs in the system.</li>
<li>\( B \): Average busy time for a resource.</li>
<li>\( U \): Average utilisation for a resource.</li>
<li>\( S \): Average service time at a resource.</li>
<li>\( \mu \): Average service rate.</li>
<li>\( I \): &quot;Request-seconds&quot;.</li>
<li>\( R \): Average response time.</li>
<li>\( Z \): Average think time.</li>
<li>\( V_k \): Average number of visits at node \( k \).</li>
<li>\( D_k \): Service demand.</li>
<li>\( D_{max} \): The maximum service demand.</li>
<li>\( D \): The sum of service demands.</li>
<li>\( a_k \): The number of arrivals to the system that move to node \( k \) directly.</li>
<li>\( \gamma_k \): The direct contribution to throughput for node \( k \) from external arrivals.</li>
<li>\( \rho \): The ratio \( \lambda / \mu \).</li>
</ul>
<h3 id="vectorsmatricies"><a class="header" href="#vectorsmatricies">Vectors/Matricies</a></h3>
<ul>
<li>\( \boldsymbol{R} \): The routing matrix of probabilities that a job goes from node \( i \) to node \( j \), indexed by \( r_{i, j} \).</li>
<li>\( \boldsymbol{Q} \): The square generator matrix for a CTMC, indexed by \( q_{i, \, j} \).</li>
</ul>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<ul>
<li>\( f(x) \): Distribution p.d.f.</li>
<li>\( F(x) \): Distribution c.d.f.</li>
<li>\( h(x) \): A function which dominates f(x).</li>
<li>\( g(x) \): h(x) but scaled such that it's total area under the curve equals 1 (p.d.f).</li>
<li>\( G(x) \): The c.d.f of g(x).</li>
<li>\( g(n, m) \): The normalising constant of a closed network with \( n \) jobs and \( m \) nodes.</li>
</ul>
<h2 id="equations"><a class="header" href="#equations">Equations</a></h2>
<p>\[
\lambda = {A \over T}
\]</p>
<hr />
<p>\[
\begin{align}
X &amp;= {C \over T} \\
&amp;= {N \over R + Z} \\
&amp;= {N \over D + Z}
\end{align}
\]</p>
<hr />
<p>\[
\begin{align}
U   &amp;= {B \over T} \\
&amp;= XS \\
U_k &amp;= D_k X
\end{align}
\]</p>
<hr />
<p>\[
S = {B \over C}
\]</p>
<hr />
<p>\[
\begin{align}
N &amp;= XR \\
&amp;= X * (R + Z) \\
R &amp;= {N \over X} - Z \\
R &amp;\le N D_{max} - Z \\
\end{align}
\]</p>
<hr />
<p>\[
V_k = {C_k \over C}
\]</p>
<hr />
<p>\[
\begin{align}
D_k &amp;= V_k S_k \\
&amp;= {U_k \over X}
\end{align}
\]</p>
<hr />
<p>\[
\gamma_k = X a_k
\]</p>
<hr />
<p>\[
\begin{align}
C_k &amp;= A a_k + C_1 r_{1, k} + C_2 r_{2, k} + \dots + C_n r_{n, k} \\
V_k &amp;= a_k + V_1 r_{1, k} + V_2 r_{2, k} + \dots + V_n r_{n, k} \\
X_k &amp;= \gamma_k + X_1 r_{1, k} X_2 + r_{2, k} + \dots + X_n r_{n, k}
\end{align}
\]</p>
<hr />
<p>\[
\begin{align}
\vec{V} (\boldsymbol{i} - \boldsymbol{R}) &amp;= \vec{a} \\
\vec{X} (\boldsymbol{i} - \boldsymbol{R}) &amp;= \vec{\gamma} \\
\vec{\lambda} (\boldsymbol{i} - \boldsymbol{R}) &amp;= \vec{\gamma}
\end{align}
\]</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
    </body>
</html>
